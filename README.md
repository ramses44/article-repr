# Воспроизведение результатов статьи

Была взята [статья](docs/article.pdf), в которой рассматривались несколько известных структур данных. 

## Суть.

Все структуры содержат слова некоторого текста. Хотим сравнить их эффективность при операции удаления слова (т.е. элемента структуры).

**Рассматривались следующие структуры:** бинарное дерево поиска, АВЛ-дерево (сбалансированное двоичное дерево), хэш-таблица, файл (по сути просто массив в памяти).

В статье приводятся сравнительные таблицы, а также объяснения, почему результаты оказались именно такими.

**Производится 2 эксперимента:** первый над обычным текстом, второй над "отсортированным" текстом (слова по алфавиту).

**Замеряются следующие параметры:** время работы (непосредственно операции удаления), потребляемая память, кол-во произведённых сравнений строк

## Воспроизведение.

В статье использовались структуры на языке C. Так что, я тоже воспроизвел их на чистом C. В статье описывались некоторые особенности реализации, которые я также постарался учесть, чтобы повторить эксперименты максимально точно.

Потребление памяти я тестировал с помощью *Valgrid*, однако так замеряется **вся** память потребляемая программой, так что я решил принять результат для файла за 0 (т.к. в случае с файлом никаких дополнительных структур не создаётся, обращаемся просто к памяти).

Время и кол-во сравнений замерялись на проведении операции удаления случайно выбранного слова. Бралось среднее по 100 тестам.

Результаты приведены в [PDF-файле](docs/my-results.pdf)

Также, было проведено тестирование на случайных данных разной размерности. Результаты этого мини-исследования со статистикой и графиками приводятся в [ноутбуке](notebook.ipynb).

## Результаты.

Конечно, числа получились далеки от совпадения. Однако, это объясняется использованием разных способов измерения и, как следствие, разных единиц измерения (для памяти и времени). По кол-ву сравнений результаты получились похожими.

Выбивается хэш-таблица. В моём случае она потребляет очень мало памяти. Вероятно, это связано со спецификой моей реализации: я аллоцирую память под бакет только, когда появляется элемент, который нужно туда записать. Скорее всего авторы статьи выделяли память под списки сразу.

## Вывод.

Основные тенденции действительно совпадают (напр., что файл показывает худшее время и кол-во сравнений, или что на обычное дерево очень плохо влиет поступление отсортированных данных).

Считаю, что результаты вопроизвести удалось, хоть и не полностью.